{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of Assistments\n",
    "\n",
    "This file contains scripts of pre-processing the Assistments data. During the process, I refered to the published DKT code (though they didn't publish their data pre-processing code).\n",
    "\n",
    "### The theano version of DKT's dataset suffers numerous problem:\n",
    "* Stale, uncorrected Assistments data.\n",
    "* Considers those without a skill label as a new skill.\n",
    "* Not in the chronological order.\n",
    "\n",
    "First, let's hash the student and skill ids according to their order (descendant appearances order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  name  age\n",
      "0    a    2\n",
      "1    b    1\n",
      "2    c    3\n",
      "  name  age\n",
      "1    b    1\n",
      "0    a    2\n",
      "2    c    3\n"
     ]
    }
   ],
   "source": [
    "# test sorting a dataframe\n",
    "df = pd.DataFrame([['a', 2], ['b', 1], ['c', 3]])\n",
    "df.columns = ['name', 'age']\n",
    "print df\n",
    "df.sort_values(by='age', inplace=True)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(401756, 30)\n",
      "(338001, 30)\n",
      "Index([u'order_id', u'assignment_id', u'user_id', u'assistment_id',\n",
      "       u'problem_id', u'original', u'correct', u'attempt_count',\n",
      "       u'ms_first_response', u'tutor_mode', u'answer_type', u'sequence_id',\n",
      "       u'student_class_id', u'position', u'type', u'base_sequence_id',\n",
      "       u'skill_id', u'skill_name', u'teacher_id', u'school_id', u'hint_count',\n",
      "       u'hint_total', u'overlap_time', u'template_id', u'answer_id',\n",
      "       u'answer_text', u'first_action', u'bottom_hint', u'opportunity',\n",
      "       u'opportunity_original'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "assitments = pd.read_csv('skill_builder_data_corrected.csv')\n",
    "print(assitments.shape)\n",
    "assitments.dropna(subset=[\"skill_id\"], inplace=True)\n",
    "#assitments = assitments[np.isfinite(assitments['skill_id'])]   # does the same thing\n",
    "assitments.dropna(subset=[\"user_id\"], inplace=True)\n",
    "assitments.sort_values(by='order_id', inplace=True)\n",
    "print(assitments.shape)\n",
    "print(assitments.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 4163 students\n"
     ]
    }
   ],
   "source": [
    "# skill 0 appears the most\n",
    "skills = assitments['skill_id'].value_counts()\n",
    "skill_hashed_to_original = skills.index.astype(int)\n",
    "skill_original_to_hashed = dict()\n",
    "for i in range(len(skill_hashed_to_original)):\n",
    "    skill_original_to_hashed[skill_hashed_to_original[i]] = i\n",
    "pickle.dump(skill_hashed_to_original, file('skill_hashed_to_original.pickle', 'w'))\n",
    "pickle.dump(skill_original_to_hashed, file('skill_original_to_hashed.pickle', 'w'))\n",
    "\n",
    "# student 0 appears the most\n",
    "students = assitments['user_id'].value_counts()\n",
    "print \"Now we have %d students\" % len(students)\n",
    "student_hashed_to_original = students.index.astype(int)\n",
    "student_original_to_hashed = dict()\n",
    "for i in range(len(student_hashed_to_original)):\n",
    "    student_original_to_hashed[student_hashed_to_original[i]] = i\n",
    "pickle.dump(student_hashed_to_original, file('student_hashed_to_original.pickle', 'w'))\n",
    "pickle.dump(student_original_to_hashed, file('student_original_to_hashed.pickle', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to generate our data file. To train a basic DKT, we only need student_id, skill_id and correct. Other fields, including sequence and assignment ids are not necessary, though probably useful in the future.\n",
    "\n",
    "*If we take time elapse into consideration (to better simulate forgetting a skill), will the DKT performs better?*\n",
    "\n",
    "Our output file should be grouped according to students (i.e., the sequence of each student's actions). The actions shall be in the order of order_id, rather than grouped by skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 338001 records\n"
     ]
    }
   ],
   "source": [
    "# output file\n",
    "output = file('assistment_for_dkt.csv', 'w')\n",
    "output.write('student,skill,correct\\n')\n",
    "student_list = student_original_to_hashed.keys()[:]\n",
    "random.shuffle(student_list)\n",
    "record_cnt = 0\n",
    "line2write = ''\n",
    "for student in student_list:\n",
    "    student_sequence = assitments[assitments['user_id'] == student]\n",
    "    student_id = student_original_to_hashed[student]\n",
    "    skill_list = student_sequence['skill_id'].values\n",
    "    correct_list = student_sequence['correct'].values\n",
    "    for i in range(len(student_sequence)):\n",
    "        line2write += (str(student_id) + ',' + \\\n",
    "                     str(skill_original_to_hashed[int(skill_list[i])]) + \\\n",
    "                     ',' + str(int(correct_list[i])) + '\\n')\n",
    "        record_cnt += 1\n",
    "output.write(line2write)\n",
    "output.flush()\n",
    "output.close()\n",
    "print \"wrote %d records\" % record_cnt\n",
    "# Do not forget to flush and close file after you are done writing!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a cleaned dataset with following improvement:\n",
    "* Originated from the corrected data from the website.\n",
    "* Discarded all records with unlabeled skill.\n",
    "* Sorted according to order_id, i.e. timestamp.\n",
    "\n",
    "Remaining Issue:\n",
    "* Problems related to multiple skills are treated as a sequence of separated problems of different (single) skills.\n",
    "\n",
    "Actually this is not that big of a drawback and kinda reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4163.000000\n",
      "mean       81.191689\n",
      "std       162.160104\n",
      "min         1.000000\n",
      "25%         9.000000\n",
      "50%        23.000000\n",
      "75%        69.000000\n",
      "max      1295.000000\n",
      "Name: user_id, dtype: float64\n",
      "338001\n"
     ]
    }
   ],
   "source": [
    "# padding: time window\n",
    "student_counts = assitments['user_id'].value_counts()\n",
    "print student_counts.describe()\n",
    "print np.sum(student_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converting Mozer's dirty data to our format to test\n",
    "dirty_file = file(\"assistments_dirty.txt\")\n",
    "dirty_target = file(\"assistment_dirty_for_dkt.csv\", \"w\")\n",
    "\n",
    "dirty_target.write(\"student,skill,correct\\n\")\n",
    "for line in dirty_file:\n",
    "    line = line.split()\n",
    "    dirty_target.write(line[0] + \",\" + line[1] + \",\" + line[2] + \"\\n\")\n",
    "dirty_target.flush()\n",
    "dirty_target.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
