{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to .py file\n",
    "To better organize the code, we need to redo the code to a .py file. Also we need to refactory the code a bit for easier usage and structure. The original DKT file is working, but we just need it to be clearer thus easier to manage.\n",
    "\n",
    "Structure of codes:\n",
    "* hyperparameters.py: Tunable hyperparameters and every parameter determined by dataset.\n",
    "* data_generator.py: Read dataset file and pad it into batches.\n",
    "* dkt_graph.py: construct the tensorflow graph for dkt.\n",
    "* graph_runner.py: run graph with certain specifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator\n",
    "In order to be able to shuffle it before every epoch, we need to arrange training data in a list of tuple: *[batch_maxlen, sequences, inputs, skills, results]*. We can do the same for the testing data.\n",
    "\n",
    "Before we pad sequence or anything, we do the the binning first.\n",
    "\n",
    "The iteration and shuffling of the dataset would be put into the Tensorflow session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 2803 student sequences\n",
      "2238 sequences, 61746 records for train\n",
      "565 sequences, 14821 records for test\n",
      "all batch generated\n"
     ]
    }
   ],
   "source": [
    "# test data generator\n",
    "from Hyperparameter import *\n",
    "from DataGenerator import *\n",
    "\n",
    "#hps = Hyperparameter(dataset_file='Assistments/assistment_for_dkt.csv',\n",
    "#                     split_file='Assistments/split_basic.csv')\n",
    "\n",
    "hps = Hyperparameter(dataset_file='Assistments/assistment_for_dkt.csv',\n",
    "                     skill_cut = 5, batch_size = 5,\n",
    "                     split_file='Assistments/split_random.csv')\n",
    "data_generator = DataGenerator(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448 train batches\n",
      "113 test batches\n",
      "76567 records in processed dataset\n",
      "220802 correct answers in original dataset\n",
      "49374 correct answers in processed dataset\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('Assistments/assistment_for_dkt.csv')\n",
    "\n",
    "# sanity check of the batches: unskewed version (we do not skew it here!)\n",
    "# batches\n",
    "print \"%d train batches\" % len(data_generator.train_batches)\n",
    "print \"%d test batches\" % len(data_generator.test_batches)\n",
    "\n",
    "# records_cnt\n",
    "record_cnt = 0\n",
    "for batch in data_generator.train_batches:\n",
    "    for step in batch.sequences:\n",
    "        for record in step:\n",
    "            if record[0] != -1:\n",
    "                record_cnt += 1\n",
    "for batch in data_generator.test_batches:\n",
    "    for step in batch.sequences:\n",
    "        for record in step:\n",
    "            if record[0] != -1:\n",
    "                record_cnt += 1\n",
    "print \"%d records in processed dataset\" % record_cnt\n",
    "\n",
    "# correct answers\n",
    "print \"%d correct answers in original dataset\" % np.sum(dataset['correct'])\n",
    "correct_sum = 0\n",
    "for batch in data_generator.train_batches:\n",
    "    correct_sum += np.sum(batch.result_labels)\n",
    "for batch in data_generator.test_batches:\n",
    "    correct_sum += np.sum(batch.result_labels)\n",
    "print \"%d correct answers in processed dataset\" % correct_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6 6 6\n",
      "5 5 5\n",
      "results:\n",
      "[0, 0, 0, 1, 0]\n",
      "[0, 0, 1, 1, 1]\n",
      "[1, 1, 0, 1, 1]\n",
      "[1, 1, 0, 1, 1]\n",
      "[1, 1, 0, 1, 1]\n",
      "[0, 0, 0, 0, 1]\n",
      "\n",
      "sequences:\n",
      "[[0, 0], [1, 0], [4, 0], [3, 1], [4, 0]]\n",
      "[[0, 0], [1, 0], [4, 1], [3, 1], [4, 1]]\n",
      "[[0, 1], [1, 1], [4, 0], [2, 1], [4, 1]]\n",
      "[[0, 1], [1, 1], [4, 0], [2, 1], [4, 1]]\n",
      "[[0, 1], [1, 1], [4, 0], [2, 1], [4, 1]]\n",
      "[[-1, -1], [-1, -1], [4, 0], [3, 0], [4, 1]]\n",
      "\n",
      "skill_labels:\n",
      "[ 1.  0.  0.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.]\n",
      "\n",
      "[ 0.  1.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.]\n",
      "\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "\n",
      "[ 0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  1.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  1.  0.]\n",
      "\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  1.]\n",
      "\n",
      "\n",
      "inputs:\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      "\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "\n",
      "[[array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.])], [array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.])], [array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.])], [array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.])], [array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.])], [array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]), array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.])]]\n"
     ]
    }
   ],
   "source": [
    "# show case in a smaller dataset\n",
    "batch = data_generator.train_batches[107]\n",
    "batch_size = 5\n",
    "maxlen = batch.maxlen\n",
    "print maxlen, len(batch.inputs), len(batch.skill_labels), len(batch.result_labels)\n",
    "print len(batch.inputs[0]), len(batch.skill_labels[0]), len(batch.result_labels[0])\n",
    "print \"results:\"\n",
    "for i in range(maxlen):\n",
    "    print batch.result_labels[i]\n",
    "print '\\nsequences:'\n",
    "for i in range(maxlen):\n",
    "    print batch.sequences[i]\n",
    "print '\\nskill_labels:'\n",
    "for i in range(batch_size):\n",
    "    for j in range(maxlen):\n",
    "        print batch.skill_labels[j][i]\n",
    "    print ''\n",
    "print '\\ninputs:'\n",
    "for i in range(batch_size):\n",
    "    for j in range(maxlen):\n",
    "        print batch.inputs[j][i]\n",
    "    print ''\n",
    "    \n",
    "print batch.inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DKT Graph and Runner\n",
    "Test the remodeled DKT graph and runner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 4163 student sequences\n",
      "3330 sequences, 274569 records for train\n",
      "833 sequences, 63432 records for test\n",
      "all batch generated\n"
     ]
    }
   ],
   "source": [
    "from DKTGraph import *\n",
    "from DKTRunner import *\n",
    "\n",
    "hps = Hyperparameter(dataset_file='Assistments/assistment_for_dkt.csv',\n",
    "                     split_file='Assistments/split_basic.csv')\n",
    "data_generator = DataGenerator(hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for batch in data_generator.train_batches:\n",
    "    print batch.maxlen\n",
    "for batch in data_generator.test_batches:\n",
    "    print batch.maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "range() integer end argument expected, got Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bffd4bee166a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdkt_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDKTGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdkt_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDKTRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdkt_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdkt_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gaosida/Desktop/DKT/DKTGraph.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hps)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mresult_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_int32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_actions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mskill_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_skills\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: range() integer end argument expected, got Tensor."
     ]
    }
   ],
   "source": [
    "dkt_graph = DKTGraph(hps)\n",
    "dkt_runner = DKTRunner()\n",
    "dkt_runner.train(hps, dkt_graph.graph, data_generator)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
